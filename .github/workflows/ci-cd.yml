name: MLOps CI/CD Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  build-test:
    runs-on: windows-latest
    defaults:
      run:
        shell: pwsh

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt

      - name: Start MLflow server (SQLite backend for Model Registry)
        run: |
          $db = Join-Path $env:GITHUB_WORKSPACE "mlflow.db"
          $art = Join-Path $env:GITHUB_WORKSPACE "mlartifacts"
          New-Item -ItemType Directory -Force -Path $art | Out-Null

          Start-Process -NoNewWindow -PassThru -FilePath python -ArgumentList @(
            "-m","mlflow","server",
            "--host","127.0.0.1",
            "--port","5000",
            "--backend-store-uri","sqlite:///$db",
            "--default-artifact-root",$art
          ) | Out-Null

          "MLFLOW_TRACKING_URI=http://127.0.0.1:5000" | Out-File -Append -Encoding utf8 $env:GITHUB_ENV
          "MLFLOW_REGISTRY_URI=http://127.0.0.1:5000" | Out-File -Append -Encoding utf8 $env:GITHUB_ENV
          "MLFLOW_EXPERIMENT_NAME=customer-churn-prediction" | Out-File -Append -Encoding utf8 $env:GITHUB_ENV

          Start-Sleep -Seconds 3

      - name: Reproduce pipeline with DVC
        run: |
          python -m dvc --version
          python -m dvc repro

      - name: Run tests (inference + unit)
        env:
          ENABLE_PROMETHEUS: "0"
        run: |
          pytest -q

      - name: Check model quality (F1 >= 0.85)
        run: |
          $p = "metrics\metrics.json"
          if (-not (Test-Path $p)) { throw "metrics/metrics.json not found. Ensure evaluate.py writes it." }

          $m = Get-Content $p -Raw | ConvertFrom-Json
          if ($null -eq $m.f1) { throw "metrics.json does not contain 'f1'." }

          $f1 = [double]$m.f1
          Write-Host ("F1=" + $f1)

          if ($f1 -lt 0.85) { throw ("Model quality is too low: " + $f1 + " < 0.85") }

      - name: Upload metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: metrics
          path: metrics/metrics.json
          if-no-files-found: error

  docker-smoke:
    needs: build-test
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt

      - name: Start MLflow server (SQLite backend for Model Registry)
        run: |
          mkdir -p mlartifacts
          nohup python -m mlflow server \
            --host 127.0.0.1 \
            --port 5000 \
            --backend-store-uri sqlite:///mlflow.db \
            --default-artifact-root ./mlartifacts \
            > mlflow_server.log 2>&1 &
          echo "MLFLOW_TRACKING_URI=http://127.0.0.1:5000" >> $GITHUB_ENV
          echo "MLFLOW_REGISTRY_URI=http://127.0.0.1:5000" >> $GITHUB_ENV
          echo "MLFLOW_EXPERIMENT_NAME=customer-churn-prediction" >> $GITHUB_ENV
          sleep 3

      - name: Reproduce pipeline with DVC (build exported model)
        run: |
          dvc repro
          test -f models/model.joblib

      - name: Build Docker image
        run: |
          docker build -t churn-api:ci .

      - name: Run container
        run: |
          docker run -d --rm --name churn-api -p 8000:8000 -p 8001:8001 churn-api:ci

      - name: Wait for /health
        run: |
          for i in $(seq 1 30); do
            if curl -fsS http://localhost:8000/health >/dev/null; then
              echo "Service is up"
              exit 0
            fi
            sleep 1
          done
          echo "Service did not become ready"
          docker logs churn-api || true
          exit 1

      - name: Smoke test /health and /predict
        run: |
          curl -fsS http://localhost:8000/health

          resp="$(curl -fsS -X POST http://localhost:8000/predict \
            -H 'Content-Type: application/json' \
            -d '{"customer_id":"C999999","tenure":12,"monthly_charges":75.5,"total_charges":850.0,"gender":"M","senior_citizen":0,"partner":"No","dependents":"No"}')"

          echo "$resp" | grep -q '"customer_id":"C999999"'
          echo "$resp" | grep -q '"churn_prediction"'
          echo "$resp" | grep -q '"churn_probability"'

      - name: Stop container
        if: always()
        run: |
          docker stop churn-api || true
